{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e288ebb1",
   "metadata": {},
   "source": [
    "## Web Scraping Part III\n",
    "\n",
    "This notebook is associated with the lesson titled **Introduction to Web Scraping Part III** in the Web Scraping and Data Storage Module. In this notebook we perform the following tasks:\n",
    "\n",
    "    - Dive deeper into BeautifulSoup to extract data from different table types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078a51d",
   "metadata": {},
   "source": [
    "### Parsing the Team Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.pro-football-reference.com/boxscores/202009130buf.htm\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_div = soup.find(id=\"all_team_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a213a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_encoded = bytearray(str(table_div.contents), 'utf-8')\n",
    "div_decoded = div_encoded.decode('utf-8')\n",
    "div_soup = BeautifulSoup(div_decoded, \"html.parser\")\n",
    "table_soup = div_soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2ca2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ddd49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for tr in table_soup.find('tbody').find_all('tr'):\n",
    "    header = tr.find('th').text\n",
    "    cell_contents = {td['data-stat']: td.text for td in tr.find_all(\"td\")}\n",
    "    output[header] = cell_contents\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6921f21",
   "metadata": {},
   "source": [
    "### Generalize Logic into Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table(soup, table_div_id):\n",
    "    \"\"\" Takes a BeautifulSoup object for the game stat webpage and the table id of the table that is going to be\n",
    "    scrapped. Parses through the table and creates a dictionary such that each header is a key and the cells\n",
    "    contents are the values. Converts the dictionary to a dataframe and returns the transposed dataframe.\"\"\"\n",
    "    \n",
    "    table_div = soup.find('div', id=table_div_id)\n",
    "    div_encoded = bytearray(str(table_div.contents), 'utf-8')\n",
    "    div_decoded = div_encoded.decode('utf-8')\n",
    "    div_soup = BeautifulSoup(div_decoded, \"html.parser\")\n",
    "    table_soup = div_soup.find('table')\n",
    "    output = {}\n",
    "    for tr in table_soup.find('tbody').find_all('tr'):\n",
    "        if (tr.find('th').text != \"\") and (tr.find('th').text != \"Player\"):\n",
    "            header = tr.find('th').text\n",
    "            cell_contents = {td['data-stat']: td.text for td in tr.find_all(\"td\")}\n",
    "            output[header] = cell_contents\n",
    "            \n",
    "    return pd.DataFrame(output).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_table(soup=soup, table_div_id=\"all_team_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747de51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test additional tables\n",
    "parse_table(soup, \"all_receiving_advanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b933e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test additional tables\n",
    "parse_table(soup, \"all_vis_snap_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d55ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test additional tables\n",
    "parse_table(soup, \"all_home_starters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299696ab",
   "metadata": {},
   "source": [
    "### Parsing the Scorebox Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fccc8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.pro-football-reference.com/boxscores/202009130buf.htm\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "scorebox = soup.find('div', class_=\"scorebox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704960d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scorebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde94ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [a.text for a in scorebox.find_all(\"a\") if a['href'].startswith(\"/teams\")]\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26224a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = soup.find(\"div\", class_=\"scorebox_meta\").find_all('div')[0].text\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [float(d.text) for d in scorebox.find_all('div', class_=\"score\")]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da58646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scorebox(soup):\n",
    "    \"\"\" Takes a BeautifulSoup object for the game stat webpage. Extracts the team names, the final score and the\n",
    "    date of the game and stores as a dictionary. Returns the dictionary \"\"\"\n",
    "    scorebox = soup.find('div', class_=\"scorebox\")\n",
    "    teams = [a.text for a in scorebox.find_all(\"a\") if a['href'].startswith(\"/teams\")]\n",
    "    scores = [float(d.text) for d in scorebox.find_all('div', class_=\"score\")]\n",
    "    date = soup.find(\"div\", class_=\"scorebox_meta\").find_all('div')[0].text\n",
    "    output = {\"home_team\": teams[0],\n",
    "              \"away_team\": teams[1],\n",
    "              \"home_team_score\": scores[0],\n",
    "              \"away_team_score\": scores[1],\n",
    "              \"date\": date}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f62101",
   "metadata": {},
   "outputs": [],
   "source": [
    " parse_scorebox(soup=soup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
