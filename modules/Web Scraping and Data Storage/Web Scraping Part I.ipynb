{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Part I\n",
    "\n",
    "This notebook is associated with the lesson titled **Introduction to Web Scraping Part I** in the Web Scraping and Data Storage Module. In this notebook we perform the following tasks:\n",
    "\n",
    "    - Make a request to the pro-football-reference webpage\n",
    "    - Parse through the HTML to find the data we are interested in\n",
    "    - Extract and store the data\n",
    "    - Generalize the process for all seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 Proof of Concept\n",
    "\n",
    "Below we explore fetching each team's landing page from the 2020 season. We will first demonstrate it for a single team and then generalize it for all teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 NFL Standings & Team Stats URL\n",
    "url = \"https://www.pro-football-reference.com/years/2020/\"\n",
    "\n",
    "# ping the page\n",
    "resp = requests.get(url)\n",
    "\n",
    "# store the underlying HTML\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating Table Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Soup to find the AFC Standing Table\n",
    "afc_div = soup.find(id=\"div_AFC\")\n",
    "# Within the AFC Standing Table find all team hyperlinks\n",
    "afc_links = afc_div.find_all('a')\n",
    "\n",
    "print(afc_links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for NFC\n",
    "nfc_div = soup.find(id=\"div_NFC\")\n",
    "nfc_links = nfc_div.find_all('a')\n",
    "\n",
    "print(nfc_links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalize the Process\n",
    "\n",
    "Now that productize what we have learned by exploring the 2020 season. The way the site is structure is such that all of the work we did above will apply to any season, so let's pass the year in as an argument to our new function. We can make the url dynamic by using an f-string and repeat what we did above for the AFC and the NFC. To finish up we will simply merge the two lists of links we generated and return the merged list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_team_links(year):\n",
    "    \"\"\"Takes a season year, requests the NFL Standings & Team Stats page for the given year and returns a list \n",
    "    of links to each season + team landing page. \"\"\"\n",
    "    \n",
    "    resp = requests.get(f\"https://www.pro-football-reference.com/years/{year}/\")\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    nfc_div = soup.find(id=\"div_NFC\")\n",
    "    afc_div = soup.find(id=\"div_AFC\")\n",
    "    nfc_links = nfc_div.find_all('a')\n",
    "    afc_links = afc_div.find_all('a')\n",
    "    team_links = afc_links + nfc_links\n",
    "    return team_links\n",
    "\n",
    "extract_team_links(year=2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
